{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "import numpy as np\n",
    "import torchtext.vocab\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext import data\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentiment_model.data_utils.tweet_dataset import TweetDataset, pad_batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--tweet_sentiment_extraction-bee4b4571daa6a0e\n",
      "Reusing dataset json (C:\\Users\\20172613\\.cache\\huggingface\\datasets\\json\\SetFit--tweet_sentiment_extraction-bee4b4571daa6a0e\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92091139e8754e229a1a498ff9ea448d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--tweet_sentiment_extraction-bee4b4571daa6a0e\n",
      "Reusing dataset json (C:\\Users\\20172613\\.cache\\huggingface\\datasets\\json\\SetFit--tweet_sentiment_extraction-bee4b4571daa6a0e\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a233c02e9ed14610bdd0f855f54eac75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Import GloVe Embeddings\n",
    "glove_twitter = GloVe(name=\"twitter.27B\", dim=50)\n",
    "tweet_data = load_dataset(\"SetFit/tweet_sentiment_extraction\")\n",
    "tweet_dataset = TweetDataset(split='train', pretrained_vecs=glove_twitter)\n",
    "# Instantiate vectors and ensure a 0 vector is inserted for unknown characters\n",
    "pre_embeds = glove_twitter.vectors\n",
    "pre_embeds = torch.cat((torch.zeros(2, pre_embeds.shape[1]), pre_embeds))\n",
    "embedding = nn.Embedding.from_pretrained(pre_embeds, sparse=True, padding_idx=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--tweet_sentiment_extraction-bee4b4571daa6a0e\n",
      "Reusing dataset json (C:\\Users\\20172613\\.cache\\huggingface\\datasets\\json\\SetFit--tweet_sentiment_extraction-bee4b4571daa6a0e\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2195f8a36e8940ebb224b7b7883cc7f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--tweet_sentiment_extraction-bee4b4571daa6a0e\n",
      "Reusing dataset json (C:\\Users\\20172613\\.cache\\huggingface\\datasets\\json\\SetFit--tweet_sentiment_extraction-bee4b4571daa6a0e\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a15e70a7d04340aebf9bfee7ef472a4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glove_twitter = GloVe(name=\"twitter.27B\", dim=50)\n",
    "\n",
    "# Instantiate vectors and ensure a 0 vector is inserted for unknown characters\n",
    "pre_embeds = glove_twitter.vectors\n",
    "pre_embeds = torch.cat((torch.zeros(1, pre_embeds.shape[1]), pre_embeds))\n",
    "\n",
    "# Load data:\n",
    "train_dataset = TweetDataset(split=\"train\", pretrained_vecs=glove_twitter)\n",
    "valid_dataset = TweetDataset(split=\"valid\", pretrained_vecs=glove_twitter)\n",
    "\n",
    "# Create data loaders:\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=pad_batch)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True, collate_fn=pad_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([   0, 6516,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0][1,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.2875,  0.3132, -0.2932,  0.1720, -0.6923, -0.4593,  1.3364,  0.7090,\n         0.1212,  0.1148, -0.4850, -0.0886, -3.0154, -0.5402, -1.3260,  0.3948,\n         0.1176, -0.1782, -0.3227,  0.2172,  0.0431, -0.4367, -0.5586, -0.4760,\n        -0.0952,  0.0032,  0.1192, -0.2364,  1.3234, -0.4509, -0.6584, -0.1387,\n         0.2215, -0.3581,  0.2099,  0.0549, -0.0803,  0.4894,  0.1921,  0.4556,\n        -1.6420, -0.8332, -0.1297,  0.9651, -0.1821,  0.3773, -0.1962, -0.1223,\n        -0.1050,  0.4539])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight[998]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset.vocab[\"<pad>\"]\n",
    "#tweet_dataset.vocab.lookup_token(6516)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sentiment_model.model import SentimentNet\n",
    "from sentiment_model.data_utils.tweet_dataset import pad_batch\n",
    "\n",
    "train_loader = DataLoader(tweet_dataset, batch_size=32, shuffle=True, collate_fn=pad_batch)\n",
    "len(tweet_dataset.vocab)\n",
    "\n",
    "model = SentimentNet()\n",
    "model_state_dict = torch.load(\"checkpoints/cool-bee-4/cool-bee-4-epoch-11.pth\")['model_state_dict']\n",
    "model.load_state_dict(model_state_dict)\n",
    "data, target, text_lengths = next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Token asfj;lsadj;lasdjf not found and default index is not set",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [54]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m tweet_dataset\u001B[38;5;241m.\u001B[39mvocab[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHello\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m tz \u001B[38;5;241m=\u001B[39m get_tokenizer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspacy\u001B[39m\u001B[38;5;124m\"\u001B[39m, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124men_core_web_sm\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m \u001B[43mtweet_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43masfj;lsadj;lasdjf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\sentiment\\lib\\site-packages\\torchtext\\vocab\\vocab.py:64\u001B[0m, in \u001B[0;36mVocab.__getitem__\u001B[1;34m(self, token)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mexport\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, token: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;124;03m        token: The token used to lookup the corresponding index.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;124;03m        The index corresponding to the associated token.\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Token asfj;lsadj;lasdjf not found and default index is not set"
     ]
    }
   ],
   "source": [
    "tweet_dataset.vocab['Hello']\n",
    "\n",
    "tz = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "tweet_dataset.vocab['asfj;lsadj;lasdjf']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "['Helllooo', 'how', '.', 'lkjadf', ';', 'are', 'yuou\\\\', '?']"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz(\"Helllooo how. lkjadf; are yuou\\?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "from torchtext. vocab import GloVe, vocab\n",
    "\n",
    "tokens = tz(\"Helllooo how. lkjadf; are yuou\\?\".lower())\n",
    "\n",
    "glove_twitter = GloVe(name = \"twitter.27B\", dim=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.4722,  0.6159, -0.6601, -0.1462, -0.4797, -0.5676,  0.4519,  0.4646,\n        -0.2835, -0.6584,  0.3741, -0.6437, -3.3311,  0.3133,  0.2019,  0.1715,\n         0.6436,  0.2090,  0.0325, -0.1899, -0.8975,  0.9616, -0.2340, -0.4361,\n         0.0687, -0.8583,  0.0737, -0.1705,  0.5671,  0.0952, -0.1938, -0.3952,\n         0.1049, -0.2117, -1.0626,  0.4975,  0.0692,  0.2275,  0.0324, -0.6410,\n        -0.5017,  0.0518,  0.3308,  0.7859,  1.3322, -0.0709,  0.6726,  0.2338,\n        -0.7912, -0.6818])"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_twitter.get_vecs_by_tokens()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "1193514"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vocab = vocab(glove_twitter.stoi)\n",
    "unk_token = \"<unk>\"\n",
    "unk_index = 0\n",
    "glove_vocab.insert_token(unk_token, unk_index)\n",
    "glove_vocab.set_default_index(unk_index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "if a is not None:\n",
    "    print(\"Yes\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n"
     ]
    }
   ],
   "source": [
    "tz = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(tz.ids_to_tokens[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "sentiment",
   "language": "python",
   "display_name": "sentiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}